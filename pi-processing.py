#!/usr/bin/env python3

import cv2
import numpy
import math
import time
from enum import Enum

from cscore import CameraServer, VideoSource, CvSource, VideoMode, CvSink, UsbCamera
from networktables import NetworkTablesInstance

# This class is copied directly from tape.py
# It was generated using Grip.
class GripPipeline:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsv_threshold_hue = [45.9823890977948, 99.96647827696339]
        self.__hsv_threshold_saturation = [0.0, 255.0]
        self.__hsv_threshold_value = [196.46582733812951, 255.0]

        self.hsv_threshold_output = None

        self.__find_contours_input = self.hsv_threshold_output
        self.__find_contours_external_only = False

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 35.0
        self.__filter_contours_min_perimeter = 0.0
        self.__filter_contours_min_width = 0.0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0.0
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [23.381294964028775, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None

        self.__convex_hulls_contours = self.filter_contours_output

        self.convex_hulls_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSV_Threshold0:
        self.__hsv_threshold_input = source0
        (self.hsv_threshold_output) = self.__hsv_threshold(self.__hsv_threshold_input, self.__hsv_threshold_hue, self.__hsv_threshold_saturation, self.__hsv_threshold_value)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsv_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        (self.filter_contours_output) = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)

        # Step Convex_Hulls0:
        self.__convex_hulls_contours = self.filter_contours_output
        (self.convex_hulls_output) = self.__convex_hulls(self.__convex_hulls_contours)


    @staticmethod
    def __hsv_threshold(input, hue, sat, val):
        """Segment an image based on hue, saturation, and value ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max value.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HSV)
        return cv2.inRange(out, (hue[0], sat[0], val[0]),  (hue[1], sat[1], val[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        output = []
        for contour in input_contours:
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            output.append(contour)
        return output

    @staticmethod
    def __convex_hulls(input_contours):
        """Computes the convex hulls of contours.
        Args:
            input_contours: A list of numpy.ndarray that each represent a contour.
        Returns:
            A list of numpy.ndarray that each represent a contour.
        """
        output = []
        for contour in input_contours:
            output.append(cv2.convexHull(contour))
        return output

def pointsDist(point1, point2):
    return numpy.linalg.norm(point1 - point2)

def pointsSlope(point1, point2):
    dx = point1[0] - point2[0]
    dy = point1[1] - point2[1]

    if dx == 0:
        return 99999
    
    return dy / dx

def boxLengthSlope(box):
    dist1 = pointsDist(box[0], box[1])
    dist2 = pointsDist(box[1], box[2])

    slope1 = pointsSlope(box[0], box[1])
    slope2 = pointsSlope(box[1], box[2])

    slope = slope1 if (dist1 > dist2) else slope2

    return max(dist1, dist2), slope

def boxIsReasonableRatio(box):
    dist1 = pointsDist(box[0], box[1])
    dist2 = pointsDist(box[1], box[2])

    length = max(dist1, dist2)
    width = min(dist1, dist2)

    ratio = length / width
    targetRatio = 2.25
    return abs(ratio - targetRatio) < 1.0

def boxIsReasonableAngle(box):
    length, slope = boxLengthSlope(box)

    angle = math.degrees(math.atan(abs(slope)))
    targetAngle = 90 - 14.5

    return abs(angle - targetAngle) < 25

def sortBoxCenter(box):
    center = (box[0] + box[2]) / 2
    return center[0]

def pairBoundingBox(pair):
    allPoints = numpy.concatenate(pair)
    return cv2.boundingRect(allPoints)

def pairIsReasonableRatio(pair):
    x, y, w, h = pairBoundingBox(pair)
    ratio = w / h
    targetRatio = 2.435
    return abs(ratio - targetRatio) < 1.5

def makePair(box1, box2):
    pair = (box1, box2)

    length1, slope1 = boxLengthSlope(box1)
    length2, slope2 = boxLengthSlope(box2)

    # Left/right tape angled correctly
    if (slope1 > 0 or slope2 < 0):
        return None

    # Not wildly different sizes than each other
    if (abs(length1 / length2) - 1) > 0.5:
        return None
    
    # Not at different heights (y values aren't too different)
    center1 = (box1[0][1] + box1[2][1]) / 2
    center2 = (box2[0][1] + box2[2][1]) / 2
    maxAllowedYOffset = (length1 + length2) / 2
    if (abs(center1 - center2) > maxAllowedYOffset):
        return None
    
    # Reasonable bounding box ratio
    if (not pairIsReasonableRatio(pair)):
        return None

    return pair

def makeAllPairs(boxes):
    pairs = []
    
    if (len(boxes) < 2):
        return pairs
    
    for dist in range(1, len(boxes)):
        i = 0
        while (i + dist < len(boxes)):
            pair = makePair(boxes[i], boxes[i + dist])
            if (pair == None):
                i += 1
            else:
                pairs.append(pair)
                del boxes[i]
                del boxes[i + dist - 1]
                return pairs + makeAllPairs(boxes)
    
    return pairs

def findTargetPair(pairs):
    if (len(pairs) == 0):
        return None, 0, -1
    
    bestPair = pairs[0]
    bestPairDist = 9999999999999
    bestPairIndex = -1
    for i, pair in enumerate(pairs):
        x, y, w, h = pairBoundingBox(pair)
        centerX = int(x + w / 2)

        imgWidth = img.shape[1]
        distToCenter = centerX - imgWidth / 2

        if (abs(distToCenter) < abs(bestPairDist)):
            bestPair = pair
            bestPairIndex = i
            bestPairDist = distToCenter
    
    return bestPair, bestPairDist, bestPairIndex

if __name__ == "__main__":
    team = 5980

    ntinst = NetworkTablesInstance.getDefault()
    print("Setting up NetworkTables client for team {}".format(team))
    ntinst.startClientTeam(team)
    SmartDashBoardValues = ntinst.getTable('ReflectiveTapeContours')

    imgW = 320
    imgH = 240

    print("Connecting to camera")
    cs = CameraServer.getInstance()
    cs.enableLogging()
    camera = cs.startAutomaticCapture()
    camera.setResolution(imgW, imgH)
    # camera.setExposureManual(10)
    # camera.setWhiteBalanceManual(50)
    """
    https://www.chiefdelphi.com/t/pi-3-slow-cvsink-grabframe-times/162675/5?u=pulljosh
    The other thing worth trying is setting the camera video mode to YUYV
    format instead of the default MJPEG (use SetVideoMode instead of
    SetResolution on the UsbCamera object to do this).
    """
    
    cvSink = cs.getVideo()
    outputStream = cs.putVideo("rPi Camera: Processed", imgW, imgH)

    img = numpy.zeros(shape=(imgW, imgH, 3), dtype=numpy.uint8)
    
    pipeline = GripPipeline()

    while True:
        tStart = time.time()

        # Pull frame from camera
        grabTime, img = cvSink.grabFrame(img)
        if grabTime == 0:
            outputStream.notifyError(cvSink.getError())
            print("cvSink error while getting frame")
            continue
        
        # Process image with GRIP code
        pipeline.process(img)

        tImg = time.time()

        # Find rotated bounding boxes
        contours = pipeline.convex_hulls_output
        rects = list(map(cv2.minAreaRect, contours))
        boxes = list(map(cv2.boxPoints, rects))

        tBoxesFind = time.time()

        # Filter boxes (remove false positives)
        boxes = list(filter(boxIsReasonableRatio, boxes))
        boxes = list(filter(boxIsReasonableAngle, boxes))
        boxes.sort(key=sortBoxCenter)

        tBoxesFilter = time.time()
        
        # Draw boxes
        for box in boxes:
            length, slope = boxLengthSlope(box)
            tapeSide = 'R' if slope > 0 else 'L'
            center = (
                int((box[0][0] + box[2][0]) / 2),
                int((box[0][1] + box[2][1]) / 2)
            )

            box = numpy.int0(box)
            cv2.drawContours(img, [box], 0, (0, 0, 255), 1)
            cv2.putText(img, tapeSide, center, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)
        
        tBoxesDraw = time.time()

        # Find pairs of boxes
        pairs = makeAllPairs(boxes)

        tPairs = time.time()
        
        # Find pair closest to center of screen
        bestPair, bestPairDist, bestPairIndex = findTargetPair(pairs)

        tBestPair = time.time()

        # Draw all pairs
        for i, pair in enumerate(pairs):
            if (i == bestPairIndex):
                color = (0, 255, 0) # Green
            else:
                color = (0, 255, 255) # Yellow
            
            x, y, w, h = pairBoundingBox(pair)
            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
        
        tPairsDraw = time.time()
        
        # Estimate distance from camera to best pair (inches)
        if (bestPair != None):
            contourLengths = []
            for box in bestPair:
                length, slope = boxLengthSlope(box)
                contourLengths.append(length)

            avgLength = numpy.mean(contourLengths)
            estDist = 1750 / avgLength
            estHoriz = 0.00318775 * bestPairDist * estDist
            SmartDashBoardValues.putNumber('estDist', int(estDist * 10) / 10)
            SmartDashBoardValues.putNumber('estHoriz', (estHoriz * 10) / 10)
            FOV = 100 # TODO: THIS IS PROBABLY WRONG! Just a guess. Must update.
            SmartDashBoardValues.putNumber('estAngle', bestPairDist / img.shape[1] * FOV)

        tEstDist = time.time()

        print("Putting image frame to output stream")
        outputStream.putFrame(img)

        tEnd = time.time()
        print('Times:\n=============')
        print('Get image:', tImg - tStart)
        print('Find boxes:', tBoxesFind - tImg)
        print('Filter boxes:', tBoxesFilter - tBoxesFind)
        print('Draw boxes:', tBoxesDraw - tBoxesFilter)
        print('Find pairs:', tPairs - tBoxesDraw)
        print('Get best pair:', tBestPair - tPairs)
        print('Draw pairs:', tPairsDraw - tBestPair)
        print('Est. dist:', tEstDist - tPairsDraw)
        print('Put image:', tEnd - tEstDist)
        print('FPS:', int(100 / (tEnd - tStart)) / 100)
